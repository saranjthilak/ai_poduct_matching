# üß† AI Infrastructure Challenge ‚Äì Product Matching System

Welcome to my submission for the **AI Infrastructure Coding Challenge**, where I designed and built a full **image-to-product matching pipeline** leveraging state-of-the-art **Visual Language Models (VLMs)**, **Vector Databases**, and **MongoDB**, deployed using **NVIDIA Triton Inference Server**.

---

## üöÄ Overview

This project demonstrates an **end-to-end product matching system** that:
- Accepts an input product image
- Extracts visual + textual embeddings via a quantized VLM
- Retrieves the closest match from a **vector database**
- Fetches product metadata from **MongoDB**
- Logs operations and errors via a **MongoDB logging service**

---

## üèóÔ∏è Architecture

```plaintext
              +-------------------------+
              |   Input Product Image   |
              +-----------+-------------+
                          |
                          v
           +------------------------------+
           | Triton Inference Server (VLM)|
           | - Vision Encoder (e.g., CLIP)|
           | - Text Encoder (e.g., BERT)  |
           +-------------+----------------+
                         |
     +-------------------+-------------------+
     |                                   |
     v                                   v
+------------+                +-------------------+
| Vector DB  |                |    MongoDB Store   |
| (e.g. FAISS)| <------------ |  Product Metadata  |
+------------+                +-------------------+
     |
     v
+---------------------+
| Nearest Neighbor     |
| Product Match Result |
+---------------------+
```
## üß© Project Structure
```plaintext
ai-product-matching/
‚îú‚îÄ‚îÄ app/                     # Gradio or FastAPI demo interface
‚îÇ   ‚îî‚îÄ‚îÄ ui.py
‚îÇ
‚îú‚îÄ‚îÄ docker/                  # Dockerfile & entrypoints
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ
‚îú‚îÄ‚îÄ mongo_store/             # MongoDB interface
‚îÇ   ‚îú‚îÄ‚îÄ database.py          # Handles product & log storage
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ sample_data/             # Example product data
‚îÇ   ‚îú‚îÄ‚îÄ products.json
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.npy
‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ scripts/                 # Utility scripts and pipeline runners
‚îÇ   ‚îú‚îÄ‚îÄ export_clip_onnx.py       # ‚úÖ Export vision/text encoders to ONNX
‚îÇ   ‚îú‚îÄ‚îÄ quantize_tensorrt.py      # ‚úÖ Optional: Quantize via TensorRT Python API
‚îÇ   ‚îî‚îÄ‚îÄ start_pipeline.py        # Main product matching logic
‚îÇ
‚îú‚îÄ‚îÄ triton_models/           # Model repo for NVIDIA Triton
‚îÇ   ‚îú‚îÄ‚îÄ clip_vision/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model.plan       # ‚úÖ TensorRT engine (FP16 or INT8)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.pbtxt
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ clip_text/           # Optional: if text encoder also quantized
‚îÇ       ‚îú‚îÄ‚îÄ 1/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ model.plan
‚îÇ       ‚îî‚îÄ‚îÄ config.pbtxt
‚îÇ
‚îú‚îÄ‚îÄ vector_db/               # Vector DB logic (FAISS-based)
‚îÇ   ‚îú‚îÄ‚îÄ faiss_engine.py
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ .env                     # ‚úÖ Mongo URI and other secrets
‚îú‚îÄ‚îÄ Makefile                 # Convenience CLI
‚îú‚îÄ‚îÄ pyproject.toml           # Poetry dependencies
‚îú‚îÄ‚îÄ docker-compose.yml       # ‚úÖ Triton + Mongo + Your App (to be added)
‚îî‚îÄ‚îÄ README.md

```
## ‚öôÔ∏è Setup Instructions

```
1. üì¶ Install dependencies
make setup
2. üß† Load sample data
make load-data
3. ‚ñ∂Ô∏è Run pipeline
make run
4. üéõÔ∏è Launch Gradio demo
make demo
```

---

### üê≥ Run with Docker

```markdown
üê≥ Run with Docker

üõ†Ô∏è Build images

make docker-build
make docker-up
```

---

### üß™ Tech Stack

```markdown
## üß™ Tech Stack

- **FastAPI** ‚Äì API interface for embedding and matching
- **PyTorch** ‚Äì VLM model execution
- **FAISS (mocked)** ‚Äì Efficient similarity search
- **MongoDB** ‚Äì Stores product metadata and logs
- **Triton Server** ‚Äì Model serving platform
- **Gradio** ‚Äì UI for uploading and testing matching
```

## üìù License

This project is licensed under the [MIT License](LICENSE) ¬© 2025 Saran Jaya Thilak
