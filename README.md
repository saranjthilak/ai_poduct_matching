# üß† AI Infrastructure Challenge ‚Äì Product Matching System

Welcome to my submission for the **AI Infrastructure Coding Challenge**, where I designed and built a full **image-to-product matching pipeline** leveraging state-of-the-art **Visual Language Models (VLMs)**, **Vector Databases**, and **MongoDB**, deployed using **NVIDIA Triton Inference Server**.

---

## üöÄ Overview

This project demonstrates an **end-to-end product matching system** that:
- Accepts an input product image
- Extracts visual + textual embeddings via a quantized VLM
- Retrieves the closest match from a **vector database**
- Fetches product metadata from **MongoDB**
- Logs operations and errors via a **MongoDB logging service**

---

## üèóÔ∏è Architecture

```plaintext
              +-------------------------+
              |   Input Product Image   |
              +-----------+-------------+
                          |
                          v
           +------------------------------+
           | Triton Inference Server (VLM)|
           | - Vision Encoder (e.g., CLIP)|
           | - Text Encoder (e.g., BERT)  |
           +-------------+----------------+
                         |
     +-------------------+-------------------+
     |                                   |
     v                                   v
+------------+                +-------------------+
| Vector DB  |                |    MongoDB Store   |
| (e.g. FAISS)| <------------ |  Product Metadata  |
+------------+                +-------------------+
     |
     v
+---------------------+
| Nearest Neighbor     |
| Product Match Result |
+---------------------+
```
## üß© Project Structure
```plaintext
ai-product-matching/
‚îú‚îÄ‚îÄ app/                # Gradio demo interface
‚îú‚îÄ‚îÄ docker/             # Dockerfile
‚îú‚îÄ‚îÄ mongo_store/        # MongoDB interface
‚îú‚îÄ‚îÄ sample_data/        # Mock product metadata, embeddings, and images
‚îú‚îÄ‚îÄ scripts/            # Data loaders and pipeline starters
‚îú‚îÄ‚îÄ triton_models/      # Mock Triton model configs
‚îú‚îÄ‚îÄ vector_db/          # Vector DB interface
‚îú‚îÄ‚îÄ Makefile            # Convenient CLI commands
‚îú‚îÄ‚îÄ pyproject.toml      # Poetry dependencies
‚îú‚îÄ‚îÄ docker-compose.yml  # Multi-container orchestration
```
## ‚öôÔ∏è Setup Instructions

```
1. üì¶ Install dependencies
make setup
2. üß† Load sample data
make load-data
3. ‚ñ∂Ô∏è Run pipeline
make run
4. üéõÔ∏è Launch Gradio demo
make demo
```

---

### üê≥ Run with Docker

```markdown
üê≥ Run with Docker

üõ†Ô∏è Build images

make docker-build
make docker-up
```

---

### üß™ Tech Stack

```markdown
## üß™ Tech Stack

- **FastAPI** ‚Äì API interface for embedding and matching
- **PyTorch** ‚Äì VLM model execution
- **FAISS (mocked)** ‚Äì Efficient similarity search
- **MongoDB** ‚Äì Stores product metadata and logs
- **Triton Server** ‚Äì Model serving platform
- **Gradio** ‚Äì UI for uploading and testing matching
```

## üìù License

This project is licensed under the [MIT License](LICENSE) ¬© 2025 Saran Jaya Thilak







